basic {
  # MAX_WORDS = -1
  max_span_width =7
  feature_size =10
  tempeval = False

  use_pretrained = False
  seed =1
  no_cuda = false
  report_frequency = 40
  gradient_checkpointing = False
  FLIP = False
  USE_POOLED_CONTEXT = True
  USE_ENTITY_TYPES = False
  # USE_ENTITY_PROB = False
  use_prod = True
  use_minus = False
  use_plus = False

  loss_fn = "ce"
  
# GNN related
  USE_GNN = True
    add_dummy_nodes = True
    add_sent_nodes = False
    gnn_attn_heads = 2
    gnn_num_layers = 2
    gnn_with_decoder = False

  # Learning-Related Configs
    POOLING_MAXL_RATIO = 0.5
    POOLING_REDUCTION = "max"                                                                                               
    pred_threshold = 0.2                                                                                                    
    itrs_refine = 1                                                                                                         
    residual_coef = 1.0 
    
  epochs = 100
  # starting_epoch = 1 
  transformer_learning_rate = 1e-04  # we tried 3e-5
  task_learning_rate = 0.0008
  dropout_rate = 0.2#35
  batch_size = 8 
  max_grad_norm = 1.0
  ned_pretrain_epochs = 7
  freeze_encoder = False

  entity_emb = False
  entity_type_emb_size = 1#12
  span_emb_size = 1000
  transformer = microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext
  bert_emb_size=768
  max_tokens=512 #4096 for longformer
  # span_hidden_size = 1000 
  # span_linear_2 = False
 
  mention_scorer_ffnn_size = 1000
  mention_scorer_ffnn_depth = 2

  mention_linker_ffnn_size = 1000
  mention_linker_ffnn_depth = 2
}
